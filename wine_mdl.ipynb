{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6849954",
   "metadata": {},
   "source": [
    "Predictive Modeling Tutorial Using the Wine Dataset in Python\n",
    "\n",
    "Predictive modeling involves using statistical or machine learning techniques to predict outcomes based on input data. \n",
    "\n",
    "In this tutorial, we will use the Wine dataset to build and evaluate predictive models. \n",
    "\n",
    "The Wine dataset contains the results of a chemical analysis of wines grown in a specific region of Italy, with 13 features describing the chemical properties of the wine and a target variable indicating the wine class.\n",
    "\n",
    "We will use Python libraries such as pandas, scikit-learn, and matplotlib to build and evaluate predictive models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "641be4a5",
   "metadata": {},
   "source": [
    "Import Libraries\n",
    "\n",
    "First, let's import the necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e301814a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1da3e8e",
   "metadata": {},
   "source": [
    "Load the Wine Dataset\n",
    "\n",
    "The Wine dataset is available in the scikit-learn library. \n",
    "\n",
    "Let's load it and convert it into a pandas DataFrame for easier manipulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9dc4a849",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   alcohol  malic_acid   ash  alcalinity_of_ash  magnesium  total_phenols  \\\n",
      "0    14.23        1.71  2.43               15.6      127.0           2.80   \n",
      "1    13.20        1.78  2.14               11.2      100.0           2.65   \n",
      "2    13.16        2.36  2.67               18.6      101.0           2.80   \n",
      "3    14.37        1.95  2.50               16.8      113.0           3.85   \n",
      "4    13.24        2.59  2.87               21.0      118.0           2.80   \n",
      "\n",
      "   flavanoids  nonflavanoid_phenols  proanthocyanins  color_intensity   hue  \\\n",
      "0        3.06                  0.28             2.29             5.64  1.04   \n",
      "1        2.76                  0.26             1.28             4.38  1.05   \n",
      "2        3.24                  0.30             2.81             5.68  1.03   \n",
      "3        3.49                  0.24             2.18             7.80  0.86   \n",
      "4        2.69                  0.39             1.82             4.32  1.04   \n",
      "\n",
      "   od280/od315_of_diluted_wines  proline  target  \n",
      "0                          3.92   1065.0       0  \n",
      "1                          3.40   1050.0       0  \n",
      "2                          3.17   1185.0       0  \n",
      "3                          3.45   1480.0       0  \n",
      "4                          2.93    735.0       0  \n"
     ]
    }
   ],
   "source": [
    "# Load the Wine dataset\n",
    "wine = load_wine()\n",
    "\n",
    "# Convert to pandas DataFrame\n",
    "df = pd.DataFrame(wine.data, columns=wine.feature_names)\n",
    "\n",
    "# Add the target column to the DataFrame\n",
    "df['target'] = wine.target\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b659eb35",
   "metadata": {},
   "source": [
    "Data Preprocessing\n",
    "\n",
    "Before building predictive models, we need to preprocess the data.\n",
    "\n",
    "Split the Data into Training and Testing Sets\n",
    "\n",
    "We will split the data into training and testing sets to evaluate the performance of our models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37b464c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into features (X) and target (y)\n",
    "X = df.drop('target', axis=1)\n",
    "y = df['target']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c686ca77",
   "metadata": {},
   "source": [
    "Feature Scaling\n",
    "\n",
    "Some algorithms perform better when the features are scaled. Let's standardize the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "910a0d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff4f983",
   "metadata": {},
   "source": [
    "Build Predictive Models\n",
    "\n",
    "We will build and evaluate several predictive models, including Logistic Regression, Decision Tree, Random Forest, Support Vector Machine (SVM), and K-Nearest Neighbors (KNN).\n",
    "\n",
    "Logistic Regression\n",
    "\n",
    "Logistic Regression is a linear model for classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "980682d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        14\n",
      "           1       1.00      1.00      1.00        14\n",
      "           2       1.00      1.00      1.00         8\n",
      "\n",
      "    accuracy                           1.00        36\n",
      "   macro avg       1.00      1.00      1.00        36\n",
      "weighted avg       1.00      1.00      1.00        36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize the model\n",
    "log_reg = LogisticRegression(max_iter=200)\n",
    "\n",
    "# Train the model\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_log_reg = log_reg.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy_log_reg = accuracy_score(y_test, y_pred_log_reg)\n",
    "print(f\"Logistic Regression Accuracy: {accuracy_log_reg}\")\n",
    "print(classification_report(y_test, y_pred_log_reg))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a3ab41",
   "metadata": {},
   "source": [
    "Decision Tree\n",
    "\n",
    "Decision Tree is a non-linear model that splits the data based on feature values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e58240cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Accuracy: 0.9444444444444444\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93        14\n",
      "           1       0.93      1.00      0.97        14\n",
      "           2       1.00      0.88      0.93         8\n",
      "\n",
      "    accuracy                           0.94        36\n",
      "   macro avg       0.95      0.93      0.94        36\n",
      "weighted avg       0.95      0.94      0.94        36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize the model\n",
    "dtree = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Train the model\n",
    "dtree.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_dtree = dtree.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy_dtree = accuracy_score(y_test, y_pred_dtree)\n",
    "print(f\"Decision Tree Accuracy: {accuracy_dtree}\")\n",
    "print(classification_report(y_test, y_pred_dtree))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c07c7e",
   "metadata": {},
   "source": [
    "Random Forest\n",
    "\n",
    "Random Forest is an ensemble method that combines multiple decision trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "05053f65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        14\n",
      "           1       1.00      1.00      1.00        14\n",
      "           2       1.00      1.00      1.00         8\n",
      "\n",
      "    accuracy                           1.00        36\n",
      "   macro avg       1.00      1.00      1.00        36\n",
      "weighted avg       1.00      1.00      1.00        36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize the model\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "print(f\"Random Forest Accuracy: {accuracy_rf}\")\n",
    "print(classification_report(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e4f6d0b",
   "metadata": {},
   "source": [
    "Support Vector Machine (SVM)\n",
    "\n",
    "SVM is a powerful model for classification that finds the optimal hyperplane to separate classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "25008675",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy: 0.9722222222222222\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        14\n",
      "           1       1.00      0.93      0.96        14\n",
      "           2       0.89      1.00      0.94         8\n",
      "\n",
      "    accuracy                           0.97        36\n",
      "   macro avg       0.96      0.98      0.97        36\n",
      "weighted avg       0.98      0.97      0.97        36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize the model\n",
    "svm = SVC(kernel='linear', random_state=42)\n",
    "\n",
    "# Train the model\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_svm = svm.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy_svm = accuracy_score(y_test, y_pred_svm)\n",
    "print(f\"SVM Accuracy: {accuracy_svm}\")\n",
    "print(classification_report(y_test, y_pred_svm))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72511f38",
   "metadata": {},
   "source": [
    "K-Nearest Neighbors (KNN)\n",
    "\n",
    "KNN is a simple, instance-based learning algorithm that classifies data points based on their neighbors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "68ea5bf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Accuracy: 0.9444444444444444\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.97        14\n",
      "           1       1.00      0.86      0.92        14\n",
      "           2       0.89      1.00      0.94         8\n",
      "\n",
      "    accuracy                           0.94        36\n",
      "   macro avg       0.94      0.95      0.94        36\n",
      "weighted avg       0.95      0.94      0.94        36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize the model\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "# Train the model\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_knn = knn.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy_knn = accuracy_score(y_test, y_pred_knn)\n",
    "print(f\"KNN Accuracy: {accuracy_knn}\")\n",
    "print(classification_report(y_test, y_pred_knn))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba82e030",
   "metadata": {},
   "source": [
    "Compare Model Performance\n",
    "\n",
    "Let's compare the performance of all the models we built."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "368bd22a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Model  Accuracy\n",
      "0  Logistic Regression  1.000000\n",
      "2        Random Forest  1.000000\n",
      "3                  SVM  0.972222\n",
      "1        Decision Tree  0.944444\n",
      "4                  KNN  0.944444\n"
     ]
    }
   ],
   "source": [
    "# Create a DataFrame to compare model performance\n",
    "model_comparison = pd.DataFrame({\n",
    "    'Model': ['Logistic Regression', 'Decision Tree', 'Random Forest', 'SVM', 'KNN'],\n",
    "    'Accuracy': [accuracy_log_reg, accuracy_dtree, accuracy_rf, accuracy_svm, accuracy_knn]\n",
    "})\n",
    "\n",
    "# Sort the DataFrame by accuracy\n",
    "model_comparison = model_comparison.sort_values(by='Accuracy', ascending=False)\n",
    "print(model_comparison)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
